---
layout: about
title: About
permalink: /
# subtitle: <a href='https://vail.sice.indiana.edu/'>Vehicle Autonomy and Intelligence Lab at Indiana University, Bloomington</a>.

profile:
  align: right 
  image: profile.jpg
  image_circular: false # crops the image to make it circular
  # address: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

## About Me

I am interested in developing methods that enable physical and virtual agents to safely explore their environments
through interaction and enhance their understanding of the world. By continuously improving their world model, these
agents can more effectively assist humans in completing tasks reliably and safely in uncertain, human-centered
environments.

Currently, I am working on safe reinforcement learning algorithms at Nuro, addressing challenging, safety-critical
decision-making and planning problems in the realm of self-driving vehicles.
I obtained my PhD from Indiana University, where my research centered on safe decision-making under uncertainty for
real-world robotic systems.
My work spans over multiple disciplines, including constrained stochastic optimal control, reinforcement learning, causal inference, game theory, and control as inference.

Prior to my Ph.D., I also worked on [reducing DAgger's manual labeling in imitation learning](https://www.youtube.com/watch?v=BvOjQcOTBvU&t=55s&ab_channel=JunhongXu) and [multi-task imitation learning](https://arxiv.org/abs/1808.04503) for mobile robot navigation in indoor environments.
